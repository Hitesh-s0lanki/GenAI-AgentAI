{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bb1cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e277d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## langsmith Tracking \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afff4da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001E7AF186EF0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E7AF1876D0>, root_client=<openai.OpenAI object at 0x000001E7AF1871F0>, root_async_client=<openai.AsyncOpenAI object at 0x000001E7AF186E90>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5fc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is gen AI in short ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e45ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI, often abbreviated as Gen AI, refers to a class of artificial intelligence models designed to generate new content. This can include text, images, music, and more, which resemble human-created content. These models leverage machine learning techniques, especially deep learning, to understand patterns in existing data and then create novel outputs based on that understanding. Examples include language models like GPT for text generation and tools like DALL-E for generating images from textual descriptions.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 15, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-Bc60EKlpGqMBfadg019D99gYLvtQ0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a605f0d-d4c9-4e49-855c-c0dbdda41e56-0', usage_metadata={'input_tokens': 15, 'output_tokens': 91, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa159901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the question\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebdd8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "926d6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c579020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangSmith is a comprehensive tool designed to facilitate the development and enhancement of language model applications. Created by LangChain, LangSmith focuses on critical areas such as observability, testing, and monitoring of language model-driven applications. It is tailored to bridge the gap between the initial ideation phase of an application and its subsequent launch in production, ensuring that the application performs optimally, reliably, and as intended.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 33, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9bddfca6e2', 'id': 'chatcmpl-Bc66yDzxmeenRHRLl8dQu07Kn77YS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f1aa6941-b957-4437-b156-b6f6c9eb8133-0', usage_metadata={'input_tokens': 33, 'output_tokens': 81, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7abd3c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab3f51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## String output parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1355ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78f2fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c82f6da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is an advanced toolset designed specifically for the development and debugging of language model applications. It allows developers to effectively monitor, test, and enhance the performance of their language model applications by offering features that provide deep insights and facilitate iterative improvements. With LangSmith, you can log interactions with language models, evaluate model responses, and analyze different aspects of application performance to ensure that the language applications meet desired objectives. Overall, LangSmith serves as a valuable resource for developers aiming to build reliable and efficient AI-driven applications by offering detailed analytics and tools necessary for optimizing language model outputs.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab3fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
